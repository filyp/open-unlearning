model_args:
  pretrained_model_name_or_path: "google/gemma-3-12b-pt"
  attn_implementation: 'flash_attention_2'
  torch_dtype: bfloat16
tokenizer_args:
  pretrained_model_name_or_path: "google/gemma-3-12b-pt"
template_args:
  apply_chat_template: False
# model_handler: Gemma3ForConditionalGeneration