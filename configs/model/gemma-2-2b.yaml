model_args:
  pretrained_model_name_or_path: "google/gemma-2-2b"
  attn_implementation: 'flash_attention_2'
  torch_dtype: bfloat16
tokenizer_args:
  pretrained_model_name_or_path: "google/gemma-2-2b"
template_args:
  apply_chat_template: False