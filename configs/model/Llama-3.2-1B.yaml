model_args:
  pretrained_model_name_or_path: "meta-llama/Llama-3.2-1B"
  attn_implementation: 'flash_attention_2'
  torch_dtype: bfloat16
tokenizer_args:
  pretrained_model_name_or_path: "meta-llama/Llama-3.2-1B"
template_args:
  apply_chat_template: False