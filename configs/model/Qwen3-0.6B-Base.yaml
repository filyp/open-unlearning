model_args:
  pretrained_model_name_or_path: "Qwen/Qwen3-0.6B-Base"
  # for Qwen3, flash attention conflicts with right padding
  attn_implementation: null
  torch_dtype: bfloat16
tokenizer_args:
  pretrained_model_name_or_path: "Qwen/Qwen3-0.6B-Base"
template_args:
  apply_chat_template: false