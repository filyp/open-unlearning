# @package _global_
 
defaults:
  - /trainer@relearning_trainer: finetune
  - override /model: Llama-3.2-3B
  # Delete inherited TOFU datasets from base data/unlearn.yaml
  - override /data/datasets@data.forget: null
  - override /data/datasets@data.retain: null
  - override /eval: null  # This disables the default TOFU evaluation
  - override /hydra/sweeper: optuna  # Use Optuna sweeper for --multirun

# task_name: ${model.pretrained_model_name_or_path}_${trainer.handler}

trainer:
  save_final_state: False
  args:
    report_to: wandb  # none|tensorboard|wandb|dvclive|comet_ml
    run_name: ${task_name}
    do_eval: False

tokenizer_cfg:
  max_length: 128  # for our wmdp corpora it's more than enough

eval:
  wmdp_low_mi:
    handler: WMDPLLowMIEvaluator
  recall_loss:
    handler: LossEvaluator
    dataset_name: recall
  wikitext_kl:
    handler: KLEvaluator
    dataset_name: wikitext
    disr_budget: 0.005

data:
  custom_loaders:
    - loader: wmdp_low_mi
      dataset: bio
      # dataset: cyber
      eval_on_all_questions: false
      num_examples_per_question: 3
      tokenizer: ${tokenizer_cfg}
    - loader: load_hf_and_tokenize  # fineweb bio dataset
      dataset_name: retain
      limit: 1000
      tokenizer: ${tokenizer_cfg}
      hf_args:
        path: m-a-p/FineFineWeb
        data_files:
          # for bio: (just this smallest parquet file will be enough)
          - biology/biology_000849.jsonl
          # for cyber:
          # - computer_science_and_technology/computer_science_and_technology_000000.jsonl
    - loader: load_hf_and_tokenize  # wikitext for KL eval
      dataset_name: wikitext
      hf_args:
        path: filypo/wikitext_16k
      limit: 128
      tokenizer: ${tokenizer_cfg}

relearning_trainer:
  # default loadede from finetune.yaml
  save_final_state: False
  handler: FinetuneTrainer
  args:
    optim: adamw_8bit  # sgd | adamw_8bit | paged_adamw_8bit
    learning_rate: 5e-6
    lr_scheduler_type: constant
    report_to: wandb  # none|tensorboard|wandb|dvclive|comet_ml
    run_name: ${task_name}
# Optuna sweeper config (activate with --multirun flag)
# metric_to_optimize: forget_acc_t1
# optimize_direction: minimize
metric_to_optimize: recall_loss
optimize_direction: maximize
hydra:
  sweeper:
    # hyperparam range loaded from /sweep config group in configs/trainer/*.yaml files
    _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
    storage: ${oc.env:OPTUNA_STORAGE_URL}
    study_name: ${task_name}
    direction: ${optimize_direction}
    n_trials: 50
    n_jobs: 1
    sampler:
      _target_: optuna.samplers.TPESampler
      seed: ${trainer.args.seed}  # deterministic
      # seed: ${now:%f}  # microseconds timestamp - unique per job, to avoid parallel searches duplicating trials
 
