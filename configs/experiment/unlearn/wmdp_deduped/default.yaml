# @package _global_

defaults:
  # - override /model: Llama-3.2-3B-Instruct
  # - override /model: Llama-3.2-3B
  - override /model: Llama-3.2-1B
  # Delete inherited TOFU datasets from base data/unlearn.yaml
  - override /data/datasets@data.forget: null
  - override /data/datasets@data.retain: null
  - override /eval: null  # This disables the default TOFU evaluation
  - override /hydra/sweeper: optuna  # Use Optuna sweeper for --multirun

# mode: wmdp_deduped  # needs to be overriden with CLI

trainer:
  args:
    report_to: none  # suppress the default wandb reporting in the trainer
    # report_to: wandb
    # run_name: ${task_name}  # that's the default
    num_train_epochs: 10
    seed: 42
    output_dir: ${paths.output_dir}
    save_strategy: 'no'
    do_train: True
    do_eval: False
    eval_on_start: True
    eval_strategy: epoch

tokenizer_cfg:
  max_length: 128
  padding: true
  truncation: true


data:
  custom_loaders:
    wmdp_bio_deduped:
      dataset: bio
      use_dev_split: false
      eval_on_all_questions: false
      num_examples_per_question: 3
      tokenizer: ${tokenizer_cfg}
    wikitext:
      load_as: wikitext
      batch_size: 8  # for 16 batches of 16 examples each, eval takes 3s
      num_batches: 24
      tokenizer: ${tokenizer_cfg}
    load_hf:  # fineweb bio dataset
      load_as: retain
      limit: 1000
      tokenizer: ${tokenizer_cfg}
      local_cache_path: .cache/fineweb_bio  # fast local Arrow cache
      hf_args:
        path: m-a-p/FineFineWeb
        split: train
        data_files:
          # for bio: (just this smallest parquet file will be enough)
          - biology/biology_000849.jsonl
          # for cyber:
          # - computer_science_and_technology/computer_science_and_technology_000000.jsonl

eval:
  deduped:
    handler: WMDPDedupedEvaluator
    disr_budget: 0.005  # KL Divergence budget
    # * uncomment to use wandb:
    wandb:
      project: open-unlearning-optuna
      group: ${task_name}
      name: ${task_name}${oc.select:hydra:job.num,}
      # name based on unlearning_rate
      # name: ur=${trainer.method_args.cfg.unlearning_rate}

# Optuna sweeper config (activate with --multirun flag)
hydra:
  sweeper:
    _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
    storage: ${oc.env:OPTUNA_STORAGE_URL}
    study_name: ${task_name}
    direction: maximize
    n_trials: 10000
    n_jobs: 1
    sampler:
      _target_: optuna.samplers.TPESampler
      seed: ${now:%f}  # microseconds timestamp - unique per job, to avoid parallel searches duplicating trials
      # seed: ${trainer.args.seed}  # deterministic
    # params loaded from /sweep config group (see defaults)
 
# model_id: meta-llama/Llama-3.2-1B
# model_id: meta-llama/Llama-3.2-3B
# model_id: meta-llama/Llama-3.1-8B


# relearning:
#   lr: 1e-5  # even with 1e-6, wikitext_loss has this Nike shape
#   num_epochs: 3
#   relearn_batch_size: 32  # can be higher because batches are usually shorter
#   relearning_eval:
#     handler: WMDPDedupedEvaluator
#     num_eval_batches: 16
#     # * uncomment to use wandb:
#     wandb:
#       project: ret_unlearning|src|main_runner.py
#       group: nov_test
#       name: ${task_name}