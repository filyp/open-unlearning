# @package _global_

defaults:
  - override /eval: null  # This disables the default TOFU evaluation
  - override /model: Llama-3.2-1B

# mode: wmdp_deduped  # needs to be overriden with CLI

data:
  # anchor: forget
  # forget:
  #   MUSE_forget: 
  #     args:
  #       hf_args:
  #         split: ${forget_split}
  #         path: muse-bench/MUSE-${data_split}
  # retain:
  #   MUSE_retain:
  #     args:
  #       hf_args:
  #         path: muse-bench/MUSE-${data_split}
  #         split: ${retain_split}
  

  dataset: bio
  use_dev_split: false
  num_examples_per_question: 3
  train_batch_size: 32  # can be higher because batches are usually shorter
  retain_batch_size: 12  # lowered from 16 because it caused OOM with GA
  tokenizer:
      max_length: 128
      padding: true
      truncation: true
      return_tensors: pt
  filter_model_id: Llama-3.2-1B
  # eval_on_all_questions: true  # best to just use it when not retraining
  wikitext_batch_size: 16
    

eval:
  deduped:
    handler: WMDPDedupedEvaluator
    num_eval_batches: 16
    # * uncomment to use wandb:
    # wandb:
    #   project: unlearning|src|main_runner.py
    #   group: nov_test
    #   name: ${task_name}

relearning:
  lr: 1e-5  # even with 1e-6, wikitext_loss has this Nike shape
  num_epochs: 3
  relearning_eval:
    handler: WMDPDedupedEvaluator
    num_eval_batches: 16
    # * uncomment to use wandb:
    # wandb:
    #   project: ret_unlearning|src|main_runner.py
    #   group: nov_test
    #   name: ${task_name}


# model_id: meta-llama/Llama-3.2-1B
# model_id: meta-llama/Llama-3.2-3B
# model_id: meta-llama/Llama-3.1-8B

# default experiment config
# loss_budget: 1.001
# max_num_epochs: 200

# retraining_rate: 1e-5  # even with 1e-6, wikitext_loss has this Nike shape